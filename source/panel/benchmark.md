# Learning to Retrieve In-Context Examples for Large Language Models
###### Abstract
aaaa
## 1 Introduction
1111
## 2 Related Work
2222
## 3 Preliminaries
3333
## 4 Methodology
4444
### Training Data Generation
5555
### Reward Modeling
6666
### Training LLM Retrievers with Knowledge Distillation
7777
### Evaluation of LLM Retrievers
8888
| Tables   |      Col1     |  Col2 |
|----------|:-------------:|------:|
| col 1 is |  left-aligned |   $1  |
| col 2 is |    centered   |   $2  |
| col 3 is | right-aligned |   $3  |
## 5 Experiments
### Evaluation Setup
9999
### Main Results
0000
### Training Pipeline of LLM-R
1010
### Generalization Ability of LLM-R
1212
### When does LLM-R Work and When Does it Not?
1313
### Using Different LLMs for Data Generation and Task Evaluation
1414
### Scaling the Number of In-Context Examples and Retriever Size
1515
## 7 Conclusion
1616
## Limitations
1717
## References
1818

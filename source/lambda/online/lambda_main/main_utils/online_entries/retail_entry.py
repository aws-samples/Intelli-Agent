import json
import re
import os
import random
from datetime import datetime 
from textwrap import dedent
from typing import TypedDict,Any,Annotated
import validators
from langgraph.graph import StateGraph,END
from common_logic.common_utils.lambda_invoke_utils import invoke_lambda,node_monitor_wrapper
from common_logic.common_utils.python_utils import update_nest_dict,add_messages
from common_logic.common_utils.constant import (
    LLMTaskType,
    ToolRuningMode,
    SceneType
)

from functions.lambda_retail_tools.product_information_search import goods_dict

from lambda_main.main_utils.parse_config import RetailConfigParser
from common_logic.common_utils.lambda_invoke_utils import send_trace,is_running_local
from common_logic.common_utils.logger_utils import get_logger
from common_logic.common_utils.response_utils import process_response
from common_logic.common_utils.serialization_utils import JSONEncoder
from common_logic.common_utils.s3_utils import download_file_from_s3,check_local_folder
from lambda_main.main_utils.online_entries.agent_base import build_agent_graph,tool_execution
from functions import get_tool_by_name

data_bucket_name = os.environ.get("RES_BUCKET", "aws-chatbot-knowledge-base-test")
order_info_path = "/tmp/functions/retail_tools/lambda_order_info/order_info.json"
check_local_folder(order_info_path)
download_file_from_s3(data_bucket_name, "retail_json/order_info.json", order_info_path)
order_dict = json.load(open(order_info_path))
logger = get_logger('retail_entry')

class ChatbotState(TypedDict):
    ########### input/output states ###########
    # inputs
    # origin event body
    event_body: dict
    # origianl input question
    query: str 
    # chat history between human and agent
    chat_history: Annotated[list[dict], add_messages] 
    # complete chatbot config, consumed by all the nodes
    chatbot_config: dict  
    goods_id:Any 
    # websocket connection id for the agent
    ws_connection_id: str 
    # whether to enbale stream output via ws_connection_id
    stream: bool 
    # message id related to original input question
    message_id: str = None 
    # record running states of different nodes
    trace_infos: Annotated[list[str], add_messages]
    # whether to enbale trace info update via streaming ouput
    enable_trace: bool 
    # outputs
    # final answer generated by whole app graph
    answer: Any  
    # information needed return to user, e.g. intention, context, figure and so on, anything you can get during execution
    extra_response: Annotated[dict, update_nest_dict]
    # addition kwargs which need to save into ddb
    ddb_additional_kwargs: dict
    # response of entire app
    app_response: Any

    ########### query rewrite states ###########
    # query rewrite results
    query_rewrite: str = None 

    ########### intention detection states ###########
    # intention type of retrieved intention samples in search engine, e.g. OpenSearch
    intent_type: str = None 
    # retrieved intention samples in search engine, e.g. OpenSearch
    intent_fewshot_examples: list 
    # tools of retrieved intention samples in search engine, e.g. OpenSearch
    intent_fewshot_tools: list

    ########### retriever states ###########
    # contexts information retrieved in search engine, e.g. OpenSearch
    qq_match_results: list = []
    contexts: str = None
    figure: list = None
    
    ########### agent states ###########
    # current output of agent
    agent_current_output: dict
    # record messages during agent tool choose and calling, including agent message, tool ouput and error messages
    agent_tool_history: Annotated[list[dict], add_messages] 
    # the maximum number that agent node can be called
    agent_repeated_call_limit: int 
    # the current call time of agent
    agent_current_call_number: int #
    # whehter the current call time is less than maximum number of agent call
    agent_repeated_call_validation: bool
    # function calling
    # whether the output of agent can be parsed as the valid tool calling
    function_calling_parse_ok: bool
    # whether the current parsed tool calling is run once
    function_calling_is_run_once: bool
    # current tool calls
    function_calling_parsed_tool_calls: list

    # retail data
    create_time: str
    goods_info: None
    human_goods_info: None
    agent_llm_type: str
    other_chain_kwargs: dict

# class ChatbotState(TypedDict):
#     chatbot_config: dict # chatbot config
#     query: str 
#     create_time: str 
#     ws_connection_id: str 
#     stream: bool 
#     query_rewrite: str = None  # query rewrite ret
#     intent_type: str = None # intent
#     intent_fewshot_examples: list
#     trace_infos: Annotated[list[str],add_messages]
#     message_id: str = None
#     chat_history: Annotated[list[dict],add_messages]
#     agent_tool_history: Annotated[list[dict],add_messages]
#     current_function_calls: list[str]
#     current_tool_execute_res: dict
#     debug_infos: Annotated[dict,update_nest_dict]
#     answer: Any  # final answer
#     current_monitor_infos: str 
#     extra_response: Annotated[dict,update_nest_dict]
#     contexts: str = None
#     intent_fewshot_tools: list #
#     current_agent_intent_type: str = None
#     function_calling_parsed_tool_calls:list 
#     # current_agent_tools_def: list[dict]
#     # current_agent_model_id: str
#     agent_current_output: dict
#     function_calling_parse_ok: bool
#     query_rule_classification: str
#     goods_info: None
#     human_goods_info: None
#     agent_llm_type: str
#     query_rewrite_llm_type: str
#     agent_repeated_call_limit: int # agent recursion limit
#     agent_current_call_number: int
#     enable_trace: bool
goods_info_tag = "商品信息"

####################
# nodes in lambdas #
####################

@node_monitor_wrapper
def query_preprocess(state: ChatbotState):
    output:str = invoke_lambda(
        event_body={**state,"chat_history":[]},
        lambda_name="Online_Query_Preprocess",
        lambda_module_path="lambda_query_preprocess.query_preprocess",
        handler_name="lambda_handler"
    )
    state['extra_response']['query_rewrite'] = output
    send_trace(f"\n\n **query_rewrite:** \n{output}")
    return {
            "query_rewrite":output,
            "current_monitor_infos":f"query_rewrite: {output}"
        }

@node_monitor_wrapper
def intention_detection(state: ChatbotState):
    intent_fewshot_examples = invoke_lambda(
        lambda_module_path='lambda_intention_detection.intention',
        lambda_name="Online_Intention_Detection",
        handler_name="lambda_handler",
        event_body=state 
    )
    state['extra_response']['intent_fewshot_examples'] = intent_fewshot_examples

    # send trace
    send_trace(f"\n\nintention retrieved:\n{json.dumps(intent_fewshot_examples,ensure_ascii=False,indent=2)}", state["stream"], state["ws_connection_id"])
    intent_fewshot_tools:list[str] = list(set([e['intent'] for e in intent_fewshot_examples]))
    return {
        "intent_fewshot_examples": intent_fewshot_examples,
        "intent_fewshot_tools": intent_fewshot_tools,
        "intent_type": "other"
        }

@node_monitor_wrapper
def agent(state: ChatbotState):
    goods_info = state.get('goods_info',None) or ""
    agent_tool_history = state.get('agent_tool_history',"")
    if agent_tool_history and hasattr(agent_tool_history[-1],'additional_kwargs'):
        search_result = agent_tool_history[-1]['additional_kwargs']['original'][0].get('search_result',1)
        if search_result == 0:
            context = agent_tool_history[-1]['additional_kwargs']['original'][0].get('result',"")
            system_prompt = ("你是安踏的客服助理，正在帮消费者解答问题，消费者提出的问题大多是属于商品的质量和物流规则。context列举了一些可能有关的具体场景及回复，你可以进行参考:\n"
                            "<context>\n"
                            f"{context}\n"
                            "</context>"
                            "你需要按照下面的guidelines对消费者的问题进行回答:\n"
                            "<guidelines>\n"
                            " - 回答内容为一句话，言简意赅。\n"
                            " - 如果问题与context内容不相关，就不要采用。\n"
                            " - 消费者的问题里面可能包含口语化的表达，比如鞋子开胶的意思是用胶黏合的鞋体裂开。这和胶丝遗留没有关系。\n"
                            ' - 如果问题涉及到订单号，请回复: "请稍等，正在帮您查询订单。"'
                            "</guidelines>"
                            )
            query = state['query']
            # print('llm config',state['chatbot_config']['rag_product_aftersales_config']['llm_config'])
            output:str = invoke_lambda(
                lambda_name='Online_LLM_Generate',
                lambda_module_path="lambda_llm_generate.llm_generate",
                handler_name='lambda_handler',
                event_body={
                    "llm_config": {
                        **state['chatbot_config']['rag_product_aftersales_config']['llm_config'], 
                        "system_prompt": system_prompt,
                          "intent_type": LLMTaskType.CHAT
                        },
                    "llm_input": { "query": query, "chat_history": state['chat_history']}
                    }
            )
            agent_current_call_number = state['agent_current_call_number'] + 1
            agent_current_output = {}
            agent_current_output['agent_output'] = {}
            agent_current_output['agent_output']['function_calls'] = []
            agent_current_output['agent_output']['content'] = output
            agent_current_output['current_agent_model_id'] = "qwen2-72B-instruct"
            agent_current_output['current_agent_tools_def'] = []
            return {
                "agent_current_output": agent_current_output,
                "agent_current_call_number": agent_current_call_number
            }

    # deal with once tool calling
    if state['agent_repeated_call_validation'] and state['function_calling_parse_ok'] and state['agent_tool_history']:
        tool_execute_res = state['agent_tool_history'][-1]['additional_kwargs']['raw_tool_call_results'][0]
        tool_name = tool_execute_res['name']
        output = tool_execute_res['output']
        tool = get_tool_by_name(tool_name,scene=SceneType.RETAIL)
        if tool.running_mode == ToolRuningMode.ONCE:
            send_trace("once tool")
            return {
                "answer": str(output['result']),
                "function_calling_is_run_once": True
            }
    
    other_chain_kwargs = {
                "goods_info": goods_info,
                "create_time": state['create_time'],
                "agent_current_call_number":state['agent_current_call_number']
        }
    
    response = app_agent.invoke({
        **state,
        "other_chain_kwargs":other_chain_kwargs
    })
    return response



@node_monitor_wrapper
def final_rag_retriever_lambda(state: ChatbotState):
    # call retriever
    retriever_params = state["chatbot_config"]["final_rag_retriever"]["retriever_config"]
    retriever_params["query"] = state["query"]
    output:str = invoke_lambda(
        event_body=retriever_params,
        lambda_name="Online_Functions",
        lambda_module_path="functions.functions_utils.retriever.retriever",
        handler_name="lambda_handler"
    )
    contexts = [doc['page_content'] for doc in output['result']['docs']]

    context = "\n".join(contexts)
    send_trace(f'**final_rag_retriever** {context}')
    return {"contexts": contexts}

@node_monitor_wrapper
def final_rag_llm_lambda(state:ChatbotState):
    context = "\n\n".join(state['contexts'])
    system_prompt = ("你是安踏的客服助理，正在帮消费者解答售前或者售后的问题。 <context> 中列举了一些可能有关的具体场景及回复，你可以进行参考:\n"
                    "<context>\n"
                    f"{context}\n"
                    "</context>\n"
                    "你需要按照下面的guidelines对消费者的问题进行回答:\n"
                    "<guidelines>\n"
                    " - 回答内容为一句话，言简意赅。\n"
                    " - 如果问题与context内容不相关，就不要采用。\n"
                    "</guidelines>\n"
                )
    output:str = invoke_lambda(
        lambda_name='Online_LLM_Generate',
        lambda_module_path="lambda_llm_generate.llm_generate",
        handler_name='lambda_handler',
        event_body={
            "llm_config": {
                **state['chatbot_config']['final_rag_retriever']['llm_config'],
                "system_prompt":system_prompt,
                "intent_type": LLMTaskType.CHAT},
            "llm_input": { "query": state["query"], "chat_history": state['chat_history']}
            }
        )
    return {"answer": output}

# def transfer_reply(state:ChatbotState):
#     return {"answer": "您好,我是安踏官方客服,很高兴为您服务。请问您有什么需要帮助的吗?"}


# def give_rhetorical_question(state:ChatbotState):
#     recent_tool_calling:list[dict] = state['function_calling_parsed_tool_calls'][0]
#     return {"answer": recent_tool_calling['kwargs']['question']}


# def give_final_response(state:ChatbotState):
#     recent_tool_calling:list[dict] = state['function_calling_parsed_tool_calls'][0]
#     return {"answer": recent_tool_calling['kwargs']['response']}

def rule_url_reply(state:ChatbotState):
    state["extra_response"]["current_agent_intent_type"] = "rule reply"
    if state['query'].endswith(('.jpg','.png')):
        answer = random.choice([
            "收到，亲。请问我们可以怎么为您效劳呢？",
            "您好，请问有什么需要帮助的吗？"
        ])
        return {"answer": answer}
    # product information
    r = re.findall(r"item.htm\?id=(.*)",state['query'])
    if r:
        goods_id = r[0]
    else:
        goods_id = 0
    if goods_id in goods_dict:
        # call llm to make summary of goods info
        human_goods_info = state['human_goods_info']
        output = f"您好，该商品的特点是:\n{human_goods_info}"
        if human_goods_info:
            system_prompt = (f"你是安踏的客服助理，当前用户对下面的商品感兴趣:\n"
                        f"<{goods_info_tag}>\n{human_goods_info}\n</{goods_info_tag}>\n"
                        "请你结合商品的基础信息，特别是卖点信息返回一句推荐语。"
                    )
            output:str = invoke_lambda(
                lambda_name='Online_LLM_Generate',
                lambda_module_path="lambda_llm_generate.llm_generate",
                handler_name='lambda_handler',
                event_body={
                    "llm_config": {
                        **state['chatbot_config']['rag_daily_reception_config']['llm_config'], 
                        "system_prompt": system_prompt,
                        "intent_type": LLMTaskType.CHAT},
                    "llm_input": {"query": state['query'], "chat_history": state['chat_history']}
                        }
                    )
       
        return {"answer":output}
  
    return {"answer":"您好"}

def rule_number_reply(state:ChatbotState):
    state["extra_response"]["current_agent_intent_type"] = "rule reply"
    return {"answer":"收到订单信息"}


def final_results_preparation(state: ChatbotState):
    state['ddb_additional_kwargs'] = {
        "goods_id":state['goods_id'],
        "current_agent_intent_type":state['extra_response'].get('current_agent_intent_type',"")
        }
    app_response = process_response(state['event_body'],state)
    return {"app_response": app_response}


################
# define edges #
################

def query_route(state:dict):
    # check if rule reply
    query = state['query']
    is_all_url = True
    for token in query.split():
        if not validators.url(token):
            is_all_url = False
    if is_all_url:
        return "url"
    if query.isnumeric() and len(query)>=8:
        return "number"
    else:
        return "continue"

def intent_route(state:dict):
    return state['intent_type']



def agent_route(state: dict):
    if state.get("function_calling_is_run_once",False):
        return "no need tool calling"
    
    state["agent_repeated_call_validation"] = state['agent_current_call_number'] < state['agent_repeated_call_limit']

    if state["agent_repeated_call_validation"]:
        return "valid tool calling"
    else:
        # TODO give final strategy
        raise 'final rag'

     
#############################
# define whole online graph #
#############################

app_agent = None

def build_graph(chatbot_state_cls):
    workflow = StateGraph(chatbot_state_cls)
    # add all nodes
    workflow.add_node("query_preprocess", query_preprocess)
    workflow.add_node("intention_detection", intention_detection)
    workflow.add_node("agent", agent)
    workflow.add_node("tools_execution", tool_execution)
    workflow.add_node("rule_url_reply",rule_url_reply)
    workflow.add_node("rule_number_reply",rule_number_reply)
    # workflow.add_node("rag_promotion_retriever",rag_promotion_retriever_lambda)
    # workflow.add_node("rag_promotion_llm",rag_promotion_llm_lambda)
    # workflow.add_node("final_rag_retriever",final_rag_retriever_lambda)
    # workflow.add_node("final_rag_llm",final_rag_llm_lambda)

    workflow.add_node("final_results_preparation", final_results_preparation)

    # add all edges
    workflow.set_entry_point("query_preprocess")
    workflow.add_edge("intention_detection","agent")
    workflow.add_edge("tools_execution","agent")
    # workflow.add_edge("agent",'parse_tool_calling')
    # workflow.add_edge("rag_daily_reception_retriever","rag_daily_reception_llm")
    # workflow.add_edge('rag_goods_exchange_retriever',"rag_goods_exchange_llm")
    # workflow.add_edge('rag_product_aftersales_retriever',"rag_product_aftersales_llm")
    # workflow.add_edge('rag_customer_complain_retriever',"rag_customer_complain_llm")
    # workflow.add_edge('rag_promotion_retriever',"rag_promotion_llm")
    # workflow.add_edge('final_rag_retriever',"final_rag_llm")
    
    # end
    # workflow.add_edge("transfer_reply",END)
    # workflow.add_edge("give_rhetorical_question",END)
    # workflow.add_edge("give_response_wo_tool",END)
    # workflow.add_edge("rag_daily_reception_llm",END)
    # workflow.add_edge("rag_goods_exchange_llm",END)
    # workflow.add_edge("rag_product_aftersales_llm",END)
    # workflow.add_edge("rag_customer_complain_llm",END)
    workflow.add_edge('rule_url_reply',END)
    workflow.add_edge('rule_number_reply',END)
    # workflow.add_edge("rag_promotion_llm",END)
    # workflow.add_edge("give_final_response",END)
    # workflow.add_edge("final_rag_llm",END)

    # temporal add edges for ending logic
    # add conditional edges
    workflow.add_conditional_edges(
        "query_preprocess",
        query_route,
        {
           "url":  "rule_url_reply",
           "number": "rule_number_reply",
           "continue": "intention_detection"
        }
    )

    # the results of agent planning will be evaluated and decide next step:
    # 1. valid tool calling: the agent chooses the valid tools, and the tools will be executed
    # 2. no need tool calling: the agent thinks no tool needs to be called, the final results can be generated
    workflow.add_conditional_edges(
        "agent",
        agent_route,
        {
            "valid tool calling": "tools_execution",
            "no need tool calling": "final_results_preparation",
        },
    )
    app = workflow.compile()
    return app

app = None 

def _prepare_chat_history(event_body):
    if "history_config" in event_body["chatbot_config"]:
        # experiment for chat history sep by goods_id
        goods_id = str(event_body['chatbot_config']['goods_id'])
        chat_history_by_goods_id = []
        for hist in event_body["chat_history"]:
            if goods_id == hist['additional_kwargs']['goods_id']:
                current_chat = {}
                current_chat['role'] = hist['role']
                current_chat['content'] = hist['content']
                current_chat['addional_kwargs'] = {}
                if 'goods_id' in hist['additional_kwargs']:
                    current_chat['addional_kwargs']['goods_id'] = str(hist['additional_kwargs']['goods_id'])
                chat_history_by_goods_id.append(current_chat)
        return chat_history_by_goods_id
    else:
        return event_body["chat_history"]

def retail_entry(event_body):
    """
    Entry point for the Lambda function.
    :param event_body: The event body for lambda function.
    return: answer(str)
    """
    global app,app_agent
    if app is None:
        app = build_graph(ChatbotState)
    
    if app_agent is None:
        app_agent = build_agent_graph(ChatbotState)

    # debuging
    # TODO only write when run local
    if is_running_local():
        with open('retail_entry_workflow.png','wb') as f:
            f.write(app.get_graph().draw_mermaid_png())
        
        with open('retail_entry_agent_workflow.png','wb') as f:
            f.write(app_agent.get_graph().draw_mermaid_png())
    ################################################################################
    # prepare inputs and invoke graph
    event_body['chatbot_config'] = RetailConfigParser.from_chatbot_config(event_body['chatbot_config'])
    chatbot_config = event_body['chatbot_config']
    query = event_body['query']
    stream = event_body['stream']
    create_time = chatbot_config.get('create_time',None)
    message_id = event_body['custom_message_id']
    ws_connection_id = event_body['ws_connection_id']
    enable_trace = chatbot_config["enable_trace"]
    goods_info_tag = "商品信息"
    
    goods_info = ""
    human_goods_info = ""
    goods_id = str(event_body['chatbot_config']['goods_id'])
    if goods_id:
        try:
            _goods_info = json.loads(goods_dict.get(goods_id,{}).get("goods_info",""))
            _goods_type = goods_dict.get(goods_id,{}).get("goods_type","")
        except Exception as e:
            import traceback 
            error = traceback.format_exc()
            logger.error(f"error meesasge {error}, invalid goods_id: {goods_id}")
            _goods_info = None
        

        if _goods_info:
            logger.info(_goods_info)
            if _goods_type:
                goods_info = f"商品类型: \n<goods_type>\n{_goods_type}\n</goods_type>\n"
            else:
                goods_info = ""
            goods_info += f"<{goods_info_tag}>\n"
    
            human_goods_info = ""
            for k,v in _goods_info.items():
                goods_info += f"{k}:{v}\n" 
                human_goods_info += f"{k}:{v}\n" 
            
            goods_info = goods_info.strip()
            goods_info += f"\n</{goods_info_tag}>"

    use_history = chatbot_config['use_history']
    chat_history = _prepare_chat_history(event_body) if use_history else []
    event_body['chat_history'] = chat_history
    logger.info(f'event_body:\n{json.dumps(event_body,ensure_ascii=False,indent=2,cls=JSONEncoder)}')
    
    logger.info(f"goods_info: {goods_info}")
    logger.info(f"chat_hisotry: {chat_history}")
    # invoke graph and get results
    response = app.invoke({
        "stream": stream,
        "chatbot_config": chatbot_config,
        "query": query,
        "create_time": create_time,
        "enable_trace": enable_trace,
        "trace_infos": [],
        "message_id": message_id,
        "chat_history": chat_history,
        "agent_tool_history": [],
        "ws_connection_id": ws_connection_id,
        "debug_infos": {},
        "extra_response": {},
        "goods_info":goods_info,
        "human_goods_info":human_goods_info,
        "agent_llm_type": LLMTaskType.RETAIL_TOOL_CALLING,
        "query_rewrite_llm_type":LLMTaskType.RETAIL_CONVERSATION_SUMMARY_TYPE,
        "agent_repeated_call_limit": chatbot_config['agent_repeated_call_limit'],
        "agent_current_call_number": 0,
        "current_agent_intent_type":"",
        "goods_info_tag": "商品信息",
        "goods_id": goods_id
    })
    return response['app_response']

main_chain_entry = retail_entry